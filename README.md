# MultiLabel Classification of PubMed Articles 
 
The traditional machine learning models give a lot of pain when we do not have sufficient labeled data for the specific task or domain we care about to train a reliable model.

Transfer learning allows us to deal with these scenarios by leveraging the already existing labeled data of some related task or domain. We try to store this knowledge gained in solving the source task in the source domain and apply it to our problem of interest.

In this work, I have utilized Transfer Learning utilizing BIO BERT model and Default BERT-BASE Uncased.

Also Applied Roberta For Sequence Classification and XLNet For Sequence Classification models class for Fine-Tuning the Model.

All the model performance for comparision has been logged to Weight and Biases. Check them out here?workspace=)

Model upload to Hugging Face Hub
